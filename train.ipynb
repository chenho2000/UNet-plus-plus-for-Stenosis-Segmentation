{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:25.082079Z",
     "start_time": "2025-04-10T05:02:16.541654Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# from torchviz import make_dot\n",
    "import albumentations as A\n",
    "import mlflow\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "import cv2\n",
    "from DiceBCELoss import DiceBCELoss\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255ff60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:25.087775Z",
     "start_time": "2025-04-10T05:02:25.083084Z"
    }
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"CS679_Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602c68d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:25.095794Z",
     "start_time": "2025-04-10T05:02:25.089784Z"
    }
   },
   "outputs": [],
   "source": [
    "# experiment_id = mlflow.create_experiment(f\"{EXPERIMENT_NAME}\")\n",
    "experiment = mlflow.get_experiment_by_name(f\"{EXPERIMENT_NAME}\")\n",
    "mlflow.set_experiment(f\"{EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47630d2b6ea48137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:25.117031Z",
     "start_time": "2025-04-10T05:02:25.096799Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "pin_memory = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fea3ccb2a9c5e3",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Path: \\\n",
    "stenosis_train = ARCADE('dataset/stenosis/train')\\\n",
    "syntax__test = ARCADE('dataset/syntax_/test')\\\n",
    "syntax__val = ARCADE('dataset/stenosis/val')\\\n",
    "syntax_train = ARCADE('dataset/syntax/train')\\\n",
    "syntax_test = ARCADE('dataset/syntax/test')\\\n",
    "syntax_val = ARCADE('dataset/syntax/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441aacaf2a604aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:27.902125Z",
     "start_time": "2025-04-10T05:02:25.118065Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = ARCADE('dataset/stenosis/train')[10]\n",
    "image = sample[0].reshape((512, 512))\n",
    "mask = sample[1].reshape((512, 512))\n",
    "\n",
    "plot_image_with_mask(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53350054ab2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:27.906719Z",
     "start_time": "2025-04-10T05:02:27.903129Z"
    }
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350425924c3aff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:27.915263Z",
     "start_time": "2025-04-10T05:02:27.906719Z"
    }
   },
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c7ba44425ee3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:31.558827Z",
     "start_time": "2025-04-10T05:02:27.915263Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset and apply transformations, for validation we don't need to apply any transformations\n",
    "\n",
    "train_transform = A.Compose([\n",
    "\n",
    "    A.VerticalFlip(p=0.5),\n",
    "\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "\n",
    "    A.ShiftScaleRotate(\n",
    "\n",
    "        shift_limit=0.3,\n",
    "\n",
    "        scale_limit=0.5,\n",
    "\n",
    "        rotate_limit=30,\n",
    "\n",
    "        border_mode=cv2.BORDER_REFLECT,\n",
    "\n",
    "        p=0.5\n",
    "\n",
    "    ),\n",
    "\n",
    "    A.Affine(shear=5, p=0.5),\n",
    "\n",
    "    A.Perspective(scale=(0.001, 0.001), p=0.5),\n",
    "\n",
    "    ToTensorV2()\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = A.Compose([\n",
    "\n",
    "    ToTensorV2()  # This ensures the output is in the format PyTorch expects\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "stenosis_train, stenosis_test, stenosis_val = get_loaders('dataset/stenosis/train', 'dataset/stenosis/test',\n",
    "\n",
    "                                                          'dataset/stenosis/val', batch_size, train_transform,\n",
    "\n",
    "                                                          val_transform, val_transform)\n",
    "\n",
    "\n",
    "# syntax_train, syntax_test, syntax_val = get_loaders('dataset/syntax/train', 'dataset/syntax/test', 'dataset/syntax/val', batch_size, train_transform,\n",
    "\n",
    "#                                                           val_transform, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbbb0e9e6da04a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4779c1e9d3991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:31.562834Z",
     "start_time": "2025-04-10T05:02:31.559833Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = UNetPlusPlus()\n",
    "# summary(model, (1, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af1043caa81c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:31.571142Z",
     "start_time": "2025-04-10T05:02:31.564850Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ[\"PATH\"] += os.pathsep + 'F:/Program Files/Graphviz/bin/'\n",
    "# x = torch.randn(1, 1, 512, 512)\n",
    "# y = model(x)\n",
    "# make_dot(y.mean(), params=dict(model.named_parameters()), show_attrs=True, show_saved=True).render(\"rnn_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c206a1383810e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414048ecb8f15bbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:02:31.756151Z",
     "start_time": "2025-04-10T05:02:31.578917Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UNetPlusPlus().to(device)\n",
    "\n",
    "# define the optimizer and loss function\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "best_f1, best_iou, best_dsc = 0.0, 0.0, 0.0\n",
    "\n",
    "# Using mlflow to log the model and parameters\n",
    "mlflow.start_run()\n",
    "mlflow.log_param(\"learning_rate\", lr)\n",
    "mlflow.log_param(\"epochs\", epochs)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "mlflow.log_param(\"Scaler\", \"GradScaler\")\n",
    "mlflow.log_param(\"loss_function\", \"DiceBCELoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60948d0082d0ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T05:08:28.200148Z",
     "start_time": "2025-04-10T05:02:31.757194Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm.trange(epochs):\n",
    "    # loop = tqdm.tqdm(stenosis_train, leave=True, position=0)\n",
    "    # for batch_idx, (data, targets) in enumerate(loop):\n",
    "    for batch_idx, (data, targets) in enumerate(stenosis_train):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.float().to(device=device)\n",
    "\n",
    "        # forward\n",
    "        predictions = model(data)\n",
    "\n",
    "        # if deep supervision is used, the predictions will be a list of tensors\n",
    "        if model.deep_supervision:\n",
    "            loss = 0\n",
    "            for i in range(len(predictions)):\n",
    "                loss += criterion(predictions[i], targets)\n",
    "        else:\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "        # log metrics to mlflow\n",
    "        mlflow.log_metric(\"Loss\", loss.item(), step=epoch *\n",
    "                          batch_size + batch_idx + 1)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    # update metrics\n",
    "    avg_f1, avg_iou, avg_dsc = track_metric(stenosis_val, model, device=device)\n",
    "\n",
    "    mlflow.log_metric(\"Avg F1\", avg_f1, step=epoch)\n",
    "    mlflow.log_metric(\"Avg IoU\", avg_iou, step=epoch)\n",
    "    mlflow.log_metric(\"Avg DSC\", avg_dsc, step=epoch)\n",
    "\n",
    "    # if we get a better f1 score, save the model\n",
    "    if avg_f1 > best_f1:\n",
    "        best_f1 = avg_f1\n",
    "        best_iou = avg_iou\n",
    "        best_dsc = avg_dsc\n",
    "        print(f\"Best F1: {best_f1}, IoU: {best_iou}, DSC: {best_dsc}\")\n",
    "        torch.save(model, \"./checkpoint/best.pth\".format(epoch))\n",
    "        # mlflow.log_artifact(\"./checkpoint/best.pth\".format(epoch))\n",
    "    else:\n",
    "        print(f\"F1: {avg_f1}, IoU: {avg_iou}, DSC: {avg_dsc}\")\n",
    "        torch.save(model, \"./checkpoint/last.pth\".format(epoch))\n",
    "        # mlflow.log_artifact(\"./checkpoint/last.pth\".format(epoch))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e02138",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaeaadc-ad24-45fe-ba3d-3db5280af574",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./checkpoint/best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc825e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1, avg_iou, avg_dsc = track_metric(\n",
    "    stenosis_test, model, device=device, post_processing=False)\n",
    "\n",
    "print(f\"Without post-processing: {avg_f1}, {avg_iou}, {avg_dsc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6f54e-e289-4379-90db-5c0763680095",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1, avg_iou, avg_dsc = track_metric(\n",
    "    stenosis_test, model, device=device, post_processing=600)\n",
    "\n",
    "print(f\"With post-processing: {avg_f1}, {avg_iou}, {avg_dsc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27973682-4eef-4772-9c53-091eabf35716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
